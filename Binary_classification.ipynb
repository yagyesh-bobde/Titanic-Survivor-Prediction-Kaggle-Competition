{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7df75e-465f-4765-ab17-970a69cd2991",
   "metadata": {},
   "source": [
    "# Tabular Playground Series - Oct 2021\n",
    "## Data Description\n",
    "\n",
    "This datase is from a kaggle competition. We will be predicting a binary target based on a number of feature columns given in the data. The columns are a mix of scaled continuous features and binary features.\n",
    "\n",
    "The data is synthetically generated by a GAN that was trained on real-world molecular response data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ad8e38-1dc6-4616-89d3-8bae2f65b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1f2ab1-c185-40b6-adf6-cd45b55b78c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/pranavbobde/.kaggle/kaggle.json'\n",
      "Downloading tabular-playground-series-oct-2021.zip to /Users/pranavbobde/Desktop/Tabular Playground Series October-2021\n",
      "100%|█████████████████████████████████████▉| 1.28G/1.29G [02:13<00:00, 13.3MB/s]\n",
      "100%|██████████████████████████████████████| 1.29G/1.29G [02:14<00:00, 10.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c tabular-playground-series-oct-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897ac29d-54be-444a-8bbd-4db0738aa55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Untitled.ipynb',\n",
       " 'tabular-playground-series-oct-2021.zip',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfb2c90-4d45-4ae3-8ccb-98f96d0f9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile \n",
    "\n",
    "with zipfile.ZipFile('tabular-playground-series-oct-2021.zip' , 'r') as file :\n",
    "    file.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc817987-d9d1-456a-bdfc-e2e8ef8275a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'train.csv', 'sample_submission.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1cc1a2-e24b-4c5a-86ac-aaead40efb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv', index_col='id')\n",
    "test_df= pd.read_csv('./data/test.csv', index_col='id')\n",
    "sample_df = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b635e66f-630a-4354-9a85-08e8e221889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.410993</td>\n",
       "      <td>0.176775</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>0.423543</td>\n",
       "      <td>0.476140</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.612021</td>\n",
       "      <td>0.534873</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.181004</td>\n",
       "      <td>0.473119</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.213657</td>\n",
       "      <td>0.619678</td>\n",
       "      <td>0.441593</td>\n",
       "      <td>0.230407</td>\n",
       "      <td>0.686013</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.182583</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.325950</td>\n",
       "      <td>0.207116</td>\n",
       "      <td>0.605699</td>\n",
       "      <td>0.309695</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.751107</td>\n",
       "      <td>0.536272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180240</td>\n",
       "      <td>0.494592</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.223580</td>\n",
       "      <td>0.760618</td>\n",
       "      <td>0.439211</td>\n",
       "      <td>0.432055</td>\n",
       "      <td>0.776147</td>\n",
       "      <td>0.483958</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.177172</td>\n",
       "      <td>0.495513</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>0.548819</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.562493</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0   0  0.205979  0.410993  0.176775  0.223581  0.423543  0.476140  0.413590   \n",
       "1   1  0.181004  0.473119  0.011734  0.213657  0.619678  0.441593  0.230407   \n",
       "2   2  0.182583  0.307431  0.325950  0.207116  0.605699  0.309695  0.493337   \n",
       "3   3  0.180240  0.494592  0.008367  0.223580  0.760618  0.439211  0.432055   \n",
       "4   4  0.177172  0.495513  0.014263  0.548819  0.625396  0.562493  0.117158   \n",
       "\n",
       "         f7        f8  ...  f276  f277  f278  f279  f280  f281  f282  f283  \\\n",
       "0  0.612021  0.534873  ...     0     1     0     0     0     0     0     0   \n",
       "1  0.686013  0.281971  ...     0     1     0     0     0     0     0     0   \n",
       "2  0.751107  0.536272  ...     0     0     0     1     1     0     0     0   \n",
       "3  0.776147  0.483958  ...     0     0     0     0     1     0     0     0   \n",
       "4  0.561255  0.077115  ...     0     1     1     0     1     0     0     1   \n",
       "\n",
       "   f284  target  \n",
       "0     0       1  \n",
       "1     0       1  \n",
       "2     0       1  \n",
       "3     0       1  \n",
       "4     0       1  \n",
       "\n",
       "[5 rows x 287 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2211e0e3-8533-464c-bfcb-7b42bcdb67c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 287), (500000, 286))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "675eac1a-f857-43c8-a465-78946523eb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500485\n",
       "0    499515\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d555e2-b81a-4304-93a6-e3d155357621",
   "metadata": {},
   "source": [
    "**This dataset has approx. 50% values of both the classes**. So, the base model which gives all the targets as either of the classes, has the accuracy 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "169cbe21-d931-40bc-a790-b342bf65a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.00000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.214334</td>\n",
       "      <td>0.460218</td>\n",
       "      <td>0.129253</td>\n",
       "      <td>0.277598</td>\n",
       "      <td>0.580710</td>\n",
       "      <td>0.416619</td>\n",
       "      <td>0.386532</td>\n",
       "      <td>0.654858</td>\n",
       "      <td>0.462256</td>\n",
       "      <td>0.258031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250096</td>\n",
       "      <td>0.137164</td>\n",
       "      <td>0.144793</td>\n",
       "      <td>0.130667</td>\n",
       "      <td>0.139210</td>\n",
       "      <td>0.199331</td>\n",
       "      <td>0.156065</td>\n",
       "      <td>0.183741</td>\n",
       "      <td>0.15468</td>\n",
       "      <td>0.500485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.053320</td>\n",
       "      <td>0.101316</td>\n",
       "      <td>0.120805</td>\n",
       "      <td>0.063163</td>\n",
       "      <td>0.115338</td>\n",
       "      <td>0.058231</td>\n",
       "      <td>0.133457</td>\n",
       "      <td>0.065158</td>\n",
       "      <td>0.129439</td>\n",
       "      <td>0.119081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433068</td>\n",
       "      <td>0.344021</td>\n",
       "      <td>0.351892</td>\n",
       "      <td>0.337036</td>\n",
       "      <td>0.346166</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>0.362917</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.36160</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.017994</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.051183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.181676</td>\n",
       "      <td>0.389215</td>\n",
       "      <td>0.017692</td>\n",
       "      <td>0.235342</td>\n",
       "      <td>0.497938</td>\n",
       "      <td>0.374390</td>\n",
       "      <td>0.317815</td>\n",
       "      <td>0.615372</td>\n",
       "      <td>0.363753</td>\n",
       "      <td>0.164559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.204498</td>\n",
       "      <td>0.453893</td>\n",
       "      <td>0.095496</td>\n",
       "      <td>0.264669</td>\n",
       "      <td>0.565059</td>\n",
       "      <td>0.414009</td>\n",
       "      <td>0.420260</td>\n",
       "      <td>0.648562</td>\n",
       "      <td>0.475701</td>\n",
       "      <td>0.227714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.229684</td>\n",
       "      <td>0.526023</td>\n",
       "      <td>0.177717</td>\n",
       "      <td>0.305837</td>\n",
       "      <td>0.657024</td>\n",
       "      <td>0.458360</td>\n",
       "      <td>0.477140</td>\n",
       "      <td>0.692666</td>\n",
       "      <td>0.561372</td>\n",
       "      <td>0.300988</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959019</td>\n",
       "      <td>0.994818</td>\n",
       "      <td>0.979797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907889</td>\n",
       "      <td>0.972601</td>\n",
       "      <td>0.986195</td>\n",
       "      <td>0.986118</td>\n",
       "      <td>0.980994</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   f0              f1              f2              f3  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.214334        0.460218        0.129253        0.277598   \n",
       "std          0.053320        0.101316        0.120805        0.063163   \n",
       "min          0.041790        0.022016        0.000381        0.000000   \n",
       "25%          0.181676        0.389215        0.017692        0.235342   \n",
       "50%          0.204498        0.453893        0.095496        0.264669   \n",
       "75%          0.229684        0.526023        0.177717        0.305837   \n",
       "max          1.000000        0.959019        0.994818        0.979797   \n",
       "\n",
       "                   f4              f5              f6              f7  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.580710        0.416619        0.386532        0.654858   \n",
       "std          0.115338        0.058231        0.133457        0.065158   \n",
       "min          0.000000        0.000959        0.000592        0.017994   \n",
       "25%          0.497938        0.374390        0.317815        0.615372   \n",
       "50%          0.565059        0.414009        0.420260        0.648562   \n",
       "75%          0.657024        0.458360        0.477140        0.692666   \n",
       "max          1.000000        0.907889        0.972601        0.986195   \n",
       "\n",
       "                   f8              f9  ...            f276            f277  \\\n",
       "count  1000000.000000  1000000.000000  ...  1000000.000000  1000000.000000   \n",
       "mean         0.462256        0.258031  ...        0.250096        0.137164   \n",
       "std          0.129439        0.119081  ...        0.433068        0.344021   \n",
       "min          0.000990        0.051183  ...        0.000000        0.000000   \n",
       "25%          0.363753        0.164559  ...        0.000000        0.000000   \n",
       "50%          0.475701        0.227714  ...        0.000000        0.000000   \n",
       "75%          0.561372        0.300988  ...        1.000000        0.000000   \n",
       "max          0.986118        0.980994  ...        1.000000        1.000000   \n",
       "\n",
       "                 f278            f279            f280            f281  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean         0.144793        0.130667        0.139210        0.199331   \n",
       "std          0.351892        0.337036        0.346166        0.399498   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          0.000000        0.000000        0.000000        0.000000   \n",
       "75%          0.000000        0.000000        0.000000        0.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "                 f282            f283           f284          target  \n",
       "count  1000000.000000  1000000.000000  1000000.00000  1000000.000000  \n",
       "mean         0.156065        0.183741        0.15468        0.500485  \n",
       "std          0.362917        0.387273        0.36160        0.500000  \n",
       "min          0.000000        0.000000        0.00000        0.000000  \n",
       "25%          0.000000        0.000000        0.00000        0.000000  \n",
       "50%          0.000000        0.000000        0.00000        1.000000  \n",
       "75%          0.000000        0.000000        0.00000        1.000000  \n",
       "max          1.000000        1.000000        1.00000        1.000000  \n",
       "\n",
       "[8 rows x 286 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f684896-c404-44c7-bdf1-392127e2c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000000 entries, 0 to 999999\n",
      "Columns: 286 entries, f0 to target\n",
      "dtypes: float64(240), int64(46)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03a61c-d714-408e-b712-51d57fcbd86e",
   "metadata": {},
   "source": [
    "**We don't to apply scaling,encoding or imputing either 'cuz this is a beginner level dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d8fb2-fe0e-428e-8caa-b8adf7808822",
   "metadata": {},
   "source": [
    "# Train/Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb26df3f-abc9-4d83-9e58-f3fd59bc2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b51a50ca-9478-423f-94a2-879912fbb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_df.drop('target', axis=1 )\n",
    "targets= train_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "236bfb5a-f0e1-49ba-b5e9-a4fec9a2e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs , val_inputs , train_targets , val_targets = train_test_split(inputs , targets,\n",
    "                                                                          test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b091037-1bc6-4f12-a641-52648d25ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9eec61-582f-4772-ab03-2c8a4b023e3c",
   "metadata": {},
   "source": [
    "# Model Selection for classification\n",
    "## 1.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "835663c0-c47f-4d1c-aade-557d5c2dabb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for the logistic Regression model is :  0.48895398556510405\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='saga') #model\n",
    "#fit to training data\n",
    "model.fit(train_inputs , train_targets )\n",
    "#predictions on val_inputs\n",
    "preds= model.predict(val_inputs)\n",
    "#loss\n",
    "loss = np.sqrt(mean_squared_error(val_targets , preds))\n",
    "\n",
    "print(\"Loss for the logistic Regression model is : \" , loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f30fd6b-157a-42cb-9c7f-c2d1fe994d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.48895398556510405    Accuracy: 0.760924\n"
     ]
    }
   ],
   "source": [
    "print(\"loss:\", loss , \"   Accuracy:\" , accuracy_score(val_targets , preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef30323-bf23-4fb5-9180-803fd4464cf5",
   "metadata": {},
   "source": [
    "So, we've an accuracy of 76% which is way better than a base accuracy of 50%. But let's explore more models...\n",
    "\n",
    "## 2.DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06fb22-8f26-4dfb-a8d5-d7acdd366a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=1) #model\n",
    "#fit to training data\n",
    "model.fit(train_inputs , train_targets )\n",
    "#predictions on val_inputs\n",
    "preds= model.predict(val_inputs)\n",
    "#loss\n",
    "loss = np.sqrt(mean_squared_error(val_targets , preds))\n",
    "\n",
    "print(\"Loss for the logistic Regression model is : \" , loss)\n",
    "print(\"Accuracy: \" ,accuracy_score(val_targets , preds) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06222fda-55bd-4b78-b7e8-0ab4dc516c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(val_targets,preds, normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a01db-69d8-42a3-b937-9868122c215f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
